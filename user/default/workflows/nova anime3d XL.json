{"id":"c2064239-7337-4ce1-80f2-5567daf370fa","revision":0,"last_node_id":52,"last_link_id":55,"nodes":[{"id":15,"type":"CLIPTextEncode","pos":[1485.4730224609375,-315.9097900390625],"size":[210,58],"flags":{},"order":19,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":19},{"name":"text","type":"STRING","widget":{"name":"text"},"link":21}],"outputs":[{"localized_name":"Êù°‰ª∂","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[23]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"CLIPTextEncode"},"widgets_values":["(masterpiece, best quality, ultra-detailed, realistic skin texture), half-body portrait of mature western woman, seductive and confident expression, inspired by Angelina Jolie, elongated facial structure, defined cheekbones, full red lips, almond-shaped blue eyes, arched brows, thick lashes, high forehead, dense voluminous blonde hair, fair skin with light freckles, wearing fully sheer lace blouse with no solid fabric, all-over floral lace pattern, tightly stretched with strained buttons, revealing cleavage and skin beneath, slight sheen of sweat on chest, black pencil skirt visible from waist, glasses on nose, holding clipboard in one hand, other hand extended forward with curled finger, teasing gesture, eyes intensely fixed on viewer  \nin luxurious executive office, large white european-style marble ceiling with ornate moldings, no chandelier, polished wooden desk, leather sofa behind, green potted plants, floor-to-ceiling windows, warm golden sunset casting glow, ambient soft shadows, refined and intimate setting\n"],"color":"#232","bgcolor":"#353"},{"id":16,"type":"CLIPTextEncode","pos":[1485.4730224609375,-225.9100341796875],"size":[210,58],"flags":{},"order":18,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":20},{"name":"text","type":"STRING","widget":{"name":"text"},"link":22}],"outputs":[{"localized_name":"Êù°‰ª∂","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[24]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, deformed, bad hands, extra fingers, missing limbs, lowres, watermark, text, out of frame, poorly drawn face, disfigured, mutated, bad anatomy, extra limbs, gross proportions, duplicate, jpeg artifacts, ugly, unnatural skin texture, long neck, wrong perspective, messy background, noisy, oversaturated, poor lighting, asian features, anime style, full body, looking away, blank stare, futuristic elements, plastic furniture, cold lighting, incorrect finger pose, broken hand pose, closed mouth, missing teeth, no tongue, incorrect saliva flow, loose clothing, flat chest, no sweat, opaque shirt, cotton fabric, plain blouse\n"],"color":"#322","bgcolor":"#533"},{"id":37,"type":"Note","pos":[1025.625,-157.5242462158203],"size":[330,140],"flags":{},"order":0,"mode":0,"inputs":[],"outputs":[],"title":"Note - Load Checkpoint REFINER","properties":{"text":""},"widgets_values":["This is a checkpoint model loader. \n - This is set up automatically with the optimal settings for whatever SD model version you choose to use.\n - In this example, it is for the Refiner SDXL model\n\nNOTE: When loading in another person's workflow, be sure to manually choose your own *local* model. This also applies to LoRas and all their deviations."],"color":"#323","bgcolor":"#535"},{"id":17,"type":"VAEDecode","pos":[1810.726318359375,119.00452423095703],"size":[200,50],"flags":{},"order":26,"mode":0,"inputs":[{"localized_name":"Latent","name":"samples","type":"LATENT","link":25},{"localized_name":"vae","name":"vae","type":"VAE","link":34}],"outputs":[{"localized_name":"ÂõæÂÉè","name":"IMAGE","shape":3,"type":"IMAGE","slot_index":0,"links":[28]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"VAEDecode"},"widgets_values":[],"color":"#332922","bgcolor":"#593930"},{"id":41,"type":"Note","pos":[1750.7261962890625,219.00453186035156],"size":[320,120],"flags":{},"order":1,"mode":0,"inputs":[],"outputs":[],"title":"Note - VAE Decoder","properties":{"text":""},"widgets_values":["This node will take the latent data from the KSampler and, using the VAE, it will decode it into visible data\n\nVAE = Latent --> Visible\n\nThis can then be sent to the Save Image node to be saved as a PNG."],"color":"#332922","bgcolor":"#593930"},{"id":42,"type":"Note","pos":[564.5,801.1199951171875],"size":[260,210],"flags":{},"order":2,"mode":0,"inputs":[],"outputs":[],"title":"Note - Empty Latent Image","properties":{"text":""},"widgets_values":["This node sets the image's resolution in Width and Height.\n\nNOTE: For SDXL, it is recommended to use trained values listed below:\n - 1024 x 1024\n - 1152 x 896\n - 896  x 1152\n - 1216 x 832\n - 832  x 1216\n - 1344 x 768\n - 768  x 1344\n - 1536 x 640\n - 640  x 1536"],"color":"#323","bgcolor":"#535"},{"id":43,"type":"Note","pos":[1471.36376953125,-124.12007141113281],"size":[240,88],"flags":{},"order":3,"mode":0,"inputs":[],"outputs":[],"title":"Note - CLIP Encode (REFINER)","properties":{"text":""},"widgets_values":["These nodes receive the text from the prompt and use the optimal CLIP settings for the specified checkpoint model (in this case: SDXL Refiner)"],"color":"#323","bgcolor":"#535"},{"id":6,"type":"CLIPTextEncode","pos":[554.9990234375,252.5272979736328],"size":[210,58],"flags":{},"order":22,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":52},{"name":"text","type":"STRING","widget":{"name":"text"},"link":16}],"outputs":[{"localized_name":"Êù°‰ª∂","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[11]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"CLIPTextEncode"},"widgets_values":["(masterpiece, best quality, ultra-detailed, realistic skin texture), half-body portrait of mature western woman, seductive and confident expression, inspired by Angelina Jolie, elongated facial structure, defined cheekbones, full red lips, almond-shaped blue eyes, arched brows, thick lashes, high forehead, dense voluminous blonde hair, fair skin with light freckles, wearing fully sheer lace blouse with no solid fabric, all-over floral lace pattern, tightly stretched with strained buttons, revealing cleavage and skin beneath, slight sheen of sweat on chest, black pencil skirt visible from waist, glasses on nose, holding clipboard in one hand, other hand extended forward with curled finger, teasing gesture, eyes intensely fixed on viewer  \nin luxurious executive office, large white european-style marble ceiling with ornate moldings, no chandelier, polished wooden desk, leather sofa behind, green potted plants, floor-to-ceiling windows, warm golden sunset casting glow, ambient soft shadows, refined and intimate setting\n"],"color":"#232","bgcolor":"#353"},{"id":7,"type":"CLIPTextEncode","pos":[554.9990234375,342.5273132324219],"size":[210,58],"flags":{},"order":23,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":53},{"name":"text","type":"STRING","widget":{"name":"text"},"link":18}],"outputs":[{"localized_name":"Êù°‰ª∂","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[12]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"CLIPTextEncode"},"widgets_values":["blurry, deformed, bad hands, extra fingers, missing limbs, lowres, watermark, text, out of frame, poorly drawn face, disfigured, mutated, bad anatomy, extra limbs, gross proportions, duplicate, jpeg artifacts, ugly, unnatural skin texture, long neck, wrong perspective, messy background, noisy, oversaturated, poor lighting, asian features, anime style, full body, looking away, blank stare, futuristic elements, plastic furniture, cold lighting, incorrect finger pose, broken hand pose, closed mouth, missing teeth, no tongue, incorrect saliva flow, loose clothing, flat chest, no sweat, opaque shirt, cotton fabric, plain blouse\n"],"color":"#322","bgcolor":"#533"},{"id":47,"type":"PrimitiveNode","pos":[1042.827880859375,827.5728759765625],"size":[210,82],"flags":{},"order":4,"mode":0,"inputs":[],"outputs":[{"name":"INT","type":"INT","widget":{"name":"end_at_step"},"slot_index":0,"links":[43,44]}],"title":"end_at_step","properties":{"Run widget replace on values":false},"widgets_values":[20,"fixed"],"color":"#432","bgcolor":"#653"},{"id":48,"type":"Note","pos":[1041.2978515625,963.962890625],"size":[213.91000366210938,110.16999816894531],"flags":{},"order":5,"mode":0,"inputs":[],"outputs":[],"properties":{"text":""},"widgets_values":["These can be used to control the total sampling steps and the step at which the sampling switches to the refiner."],"color":"#432","bgcolor":"#653"},{"id":39,"type":"Note","pos":[554.9990234375,432.5273132324219],"size":[210,88],"flags":{},"order":6,"mode":0,"inputs":[],"outputs":[],"title":"Note - CLIP Encode (BASE)","properties":{"text":""},"widgets_values":["These nodes receive the text from the prompt and use the optimal CLIP settings for the specified checkpoint model (in this case: SDXL Base)"],"color":"#323","bgcolor":"#535"},{"id":49,"type":"MarkdownNote","pos":[-294.75518798828125,122.58385467529297],"size":[225,88],"flags":{},"order":7,"mode":0,"inputs":[],"outputs":[],"properties":{},"widgets_values":["üõà [Learn more about this workflow](https://comfyanonymous.github.io/ComfyUI_examples/sdxl/)"],"color":"#432","bgcolor":"#653"},{"id":52,"type":"Reroute (rgthree)","pos":[717.645751953125,115.23762512207031],"size":[40,30],"flags":{},"order":21,"mode":0,"inputs":[{"dir":3,"label":" ","name":"","type":"*","link":54}],"outputs":[{"dir":4,"label":" ","name":"CLIP","type":"CLIP","links":[52,53]}],"properties":{"resizable":false,"size":[40,30]}},{"id":10,"type":"KSamplerAdvanced","pos":[1007.4158325195312,199.27333068847656],"size":[300,334],"flags":{},"order":24,"mode":0,"inputs":[{"localized_name":"Ê®°Âûã","name":"model","type":"MODEL","link":55},{"localized_name":"Ê≠£Èù¢Êù°‰ª∂","name":"positive","type":"CONDITIONING","link":11},{"localized_name":"Ë¥üÈù¢Êù°‰ª∂","name":"negative","type":"CONDITIONING","link":12},{"localized_name":"LatentÂõæÂÉè","name":"latent_image","type":"LATENT","link":27},{"name":"steps","type":"INT","widget":{"name":"steps"},"link":41},{"name":"end_at_step","type":"INT","widget":{"name":"end_at_step"},"link":43}],"outputs":[{"localized_name":"Latent","name":"LATENT","shape":3,"type":"LATENT","slot_index":0,"links":[13]}],"title":"KSampler (Advanced) - BASE","properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"KSamplerAdvanced"},"widgets_values":["enable",1102433730401191,"randomize",30,8,"euler","normal",0,20,"enable"],"color":"#223","bgcolor":"#335"},{"id":40,"type":"Note","pos":[988.3822631835938,147.3292694091797],"size":[451.5,424.4200134277344],"flags":{"collapsed":true},"order":8,"mode":0,"inputs":[],"outputs":[],"title":"Note - KSampler  ADVANCED General Information","properties":{"text":""},"widgets_values":["Here are the settings that SHOULD stay in place if you want this workflow to work correctly:\n - add_noise: enable = This adds random noise into the picture so the model can denoise it\n\n - return_with_leftover_noise: enable = This sends the latent image data and all it's leftover noise to the next KSampler node.\n\nThe settings to pay attention to:\n - control_after_generate = generates a new random seed after each workflow job completed.\n - steps = This is the amount of iterations you would like to run the positive and negative CLIP prompts through. Each Step will add (positive) or remove (negative) pixels based on what stable diffusion \"thinks\" should be there according to the model's training\n - cfg = This is how much you want SDXL to adhere to the prompt. Lower CFG gives you more creative but often blurrier results. Higher CFG (recommended max 10) gives you stricter results according to the CLIP prompt. If the CFG value is too high, it can also result in \"burn-in\" where the edges of the picture become even stronger, often highlighting details in unnatural ways.\n - sampler_name = This is the sampler type, and unfortunately different samplers and schedulers have better results with fewer steps, while others have better success with higher steps. This will require experimentation on your part!\n - scheduler = The algorithm/method used to choose the timesteps to denoise the picture.\n - start_at_step = This is the step number the KSampler will start out it's process of de-noising the picture or \"removing the random noise to reveal the picture within\". The first KSampler usually starts with Step 0. Starting at step 0 is the same as setting denoise to 1.0 in the regular Sampler node.\n - end_at_step = This is the step number the KSampler will stop it's process of de-noising the picture. If there is any remaining leftover noise and return_with_leftover_noise is enabled, then it will pass on the left over noise to the next KSampler (assuming there is another one)."],"color":"#223","bgcolor":"#335"},{"id":11,"type":"KSamplerAdvanced","pos":[1387.8363037109375,65.36764526367188],"size":[300,340],"flags":{},"order":25,"mode":0,"inputs":[{"localized_name":"Ê®°Âûã","name":"model","type":"MODEL","link":14},{"localized_name":"Ê≠£Èù¢Êù°‰ª∂","name":"positive","type":"CONDITIONING","link":23},{"localized_name":"Ë¥üÈù¢Êù°‰ª∂","name":"negative","type":"CONDITIONING","link":24},{"localized_name":"LatentÂõæÂÉè","name":"latent_image","type":"LATENT","link":13},{"name":"steps","type":"INT","widget":{"name":"steps"},"link":38},{"name":"start_at_step","type":"INT","widget":{"name":"start_at_step"},"link":44}],"outputs":[{"localized_name":"Latent","name":"LATENT","shape":3,"type":"LATENT","slot_index":0,"links":[25]}],"title":"KSampler (Advanced) - REFINER","properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"KSamplerAdvanced"},"widgets_values":["disable",0,"fixed",30,8,"euler","normal",20,10000,"disable"],"color":"#223","bgcolor":"#335"},{"id":4,"type":"CheckpointLoaderSimple","pos":[109.81548309326172,-316.5685119628906],"size":[350,100],"flags":{},"order":9,"mode":0,"inputs":[],"outputs":[{"localized_name":"Ê®°Âûã","name":"MODEL","type":"MODEL","slot_index":0,"links":[45]},{"localized_name":"CLIP","name":"CLIP","type":"CLIP","slot_index":1,"links":[46]},{"localized_name":"VAE","name":"VAE","type":"VAE","slot_index":2,"links":[]}],"title":"Load Checkpoint - BASE","properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["novaAnimeXL_ilV90.safetensors"],"color":"#323","bgcolor":"#535"},{"id":12,"type":"CheckpointLoaderSimple","pos":[1015.6250610351562,-308.52410888671875],"size":[350,100],"flags":{},"order":10,"mode":0,"inputs":[],"outputs":[{"localized_name":"Ê®°Âûã","name":"MODEL","shape":3,"type":"MODEL","slot_index":0,"links":[14]},{"localized_name":"CLIP","name":"CLIP","shape":3,"type":"CLIP","slot_index":1,"links":[19,20]},{"localized_name":"VAE","name":"VAE","shape":3,"type":"VAE","slot_index":2,"links":[34]}],"title":"Load Checkpoint - REFINER","properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"CheckpointLoaderSimple"},"widgets_values":["novaAnimeXL_ilV90.safetensors"],"color":"#323","bgcolor":"#535"},{"id":36,"type":"Note","pos":[125.8154525756836,-166.56919860839844],"size":[315.70001220703125,147.9600067138672],"flags":{},"order":11,"mode":0,"inputs":[],"outputs":[],"title":"Note - Load Checkpoint BASE","properties":{"text":""},"widgets_values":["This is a checkpoint model loader. \n - This is set up automatically with the optimal settings for whatever SD model version you choose to use.\n - In this example, it is for the Base SDXL model\n - This node is also used for SD1.5 and SD2.x models\n \nNOTE: When loading in another person's workflow, be sure to manually choose your own *local* model. This also applies to LoRas and all their deviations"],"color":"#323","bgcolor":"#535"},{"id":5,"type":"EmptyLatentImage","pos":[544.5,651.1199951171875],"size":[300,110],"flags":{},"order":12,"mode":0,"inputs":[],"outputs":[{"localized_name":"Latent","name":"LATENT","type":"LATENT","slot_index":0,"links":[27]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"EmptyLatentImage"},"widgets_values":[952,1600,2],"color":"#323","bgcolor":"#535"},{"id":45,"type":"PrimitiveNode","pos":[1044.827880859375,680.5728759765625],"size":[210,82],"flags":{},"order":13,"mode":0,"inputs":[],"outputs":[{"name":"INT","type":"INT","widget":{"name":"steps"},"links":[38,41]}],"title":"steps","properties":{"Run widget replace on values":false},"widgets_values":[30,"fixed"],"color":"#432","bgcolor":"#653"},{"id":51,"type":"LoraLoader","pos":[572.2459716796875,-149.87803649902344],"size":[315,126],"flags":{},"order":20,"mode":0,"inputs":[{"localized_name":"Ê®°Âûã","name":"model","type":"MODEL","link":50},{"localized_name":"CLIPCLIP","name":"clip","type":"CLIP","link":51}],"outputs":[{"localized_name":"Ê®°Âûã","name":"MODEL","type":"MODEL","links":[55]},{"localized_name":"CLIP","name":"CLIP","type":"CLIP","links":[54]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"LoraLoader"},"widgets_values":["NewFantasyCoreV4_ILL_by_VisionaryAI_.safetensors",0.6000000000000001,1]},{"id":50,"type":"LoraLoader","pos":[569.0761108398438,-328.7191467285156],"size":[315,126],"flags":{},"order":17,"mode":0,"inputs":[{"localized_name":"Ê®°Âûã","name":"model","type":"MODEL","link":45},{"localized_name":"CLIPCLIP","name":"clip","type":"CLIP","link":46}],"outputs":[{"localized_name":"Ê®°Âûã","name":"MODEL","type":"MODEL","links":[50]},{"localized_name":"CLIP","name":"CLIP","type":"CLIP","links":[51]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.44","Node name for S&R":"LoraLoader"},"widgets_values":["AddMicroDetails_Illustrious_v4.safetensors",1.0000000000000002,1]},{"id":38,"type":"Note","pos":[126.73999786376953,534.1799926757812],"size":[284.3299865722656,123.88999938964844],"flags":{},"order":14,"mode":0,"inputs":[],"outputs":[],"title":"Note - Text Prompts","properties":{"text":""},"widgets_values":["blurry, deformed, bad hands, extra fingers, missing limbs, lowres, watermark, text, out of frame, poorly drawn face, disfigured, mutated, bad anatomy, extra limbs, gross proportions, duplicate, jpeg artifacts, ugly, unnatural skin texture, long neck, wrong perspective, messy background, noisy, oversaturated, poor lighting, asian features, anime style, full body, looking away, blank stare, futuristic elements, plastic furniture, cold lighting, incorrect finger pose, broken hand pose, closed mouth, missing teeth, no tongue, incorrect saliva flow, loose clothing, flat chest, no sweat, opaque shirt, cotton fabric, plain blouse\n"],"color":"#323","bgcolor":"#535"},{"id":14,"type":"PrimitiveNode","pos":[117.73999786376953,335.17999267578125],"size":[300,160],"flags":{},"order":15,"mode":0,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","widget":{"name":"text"},"slot_index":0,"links":[18,22]}],"title":"Negative Prompt (Text)","properties":{"Run widget replace on values":false},"widgets_values":["blurry, deformed, bad hands, extra fingers, missing limbs, lowres, watermark, text, out of frame, poorly drawn face, disfigured, mutated, bad anatomy, extra limbs, gross proportions, duplicate, jpeg artifacts, ugly, unnatural skin texture, long neck, wrong perspective, messy background, noisy, oversaturated, poor lighting, asian features, anime style, full body, looking away, blank stare, futuristic elements, plastic furniture, cold lighting, incorrect finger pose, broken hand pose, closed mouth, missing teeth, no tongue, incorrect saliva flow, loose clothing, flat chest, no sweat, opaque shirt, cotton fabric, plain blouse\n"],"color":"#322","bgcolor":"#533"},{"id":19,"type":"SaveImage","pos":[1365.35498046875,480.2456970214844],"size":[991.166259765625,838.9091186523438],"flags":{},"order":27,"mode":0,"inputs":[{"localized_name":"ÂõæÁâá","name":"images","type":"IMAGE","link":28}],"outputs":[],"properties":{"cnr_id":"comfy-core","ver":"0.3.44"},"widgets_values":["wzy",""],"color":"#222","bgcolor":"#000"},{"id":13,"type":"PrimitiveNode","pos":[117.73999786376953,135.17999267578125],"size":[300,160],"flags":{},"order":16,"mode":0,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","widget":{"name":"text"},"slot_index":0,"links":[16,21]}],"title":"Positive Prompt (Text)","properties":{"Run widget replace on values":false},"widgets_values":["(masterpiece, best quality, ultra-detailed, realistic skin texture), half-body portrait of mature western woman, seductive and confident expression, inspired by Angelina Jolie, elongated facial structure, defined cheekbones, full red lips, almond-shaped blue eyes, arched brows, thick lashes, high forehead, dense voluminous blonde hair, fair skin with light freckles, wearing fully sheer lace blouse with no solid fabric, all-over floral lace pattern, tightly stretched with strained buttons, revealing cleavage and skin beneath, slight sheen of sweat on chest, black pencil skirt visible from waist, glasses on nose, holding clipboard in one hand, other hand extended forward with curled finger, teasing gesture, eyes intensely fixed on viewer  \nin luxurious executive office, large white european-style marble ceiling with ornate moldings, no chandelier, polished wooden desk, leather sofa behind, green potted plants, floor-to-ceiling windows, warm golden sunset casting glow, ambient soft shadows, refined and intimate setting\n"],"color":"#232","bgcolor":"#353"}],"links":[[11,6,0,10,1,"CONDITIONING"],[12,7,0,10,2,"CONDITIONING"],[13,10,0,11,3,"LATENT"],[14,12,0,11,0,"MODEL"],[16,13,0,6,1,"STRING"],[18,14,0,7,1,"STRING"],[19,12,1,15,0,"CLIP"],[20,12,1,16,0,"CLIP"],[21,13,0,15,1,"STRING"],[22,14,0,16,1,"STRING"],[23,15,0,11,1,"CONDITIONING"],[24,16,0,11,2,"CONDITIONING"],[25,11,0,17,0,"LATENT"],[27,5,0,10,3,"LATENT"],[28,17,0,19,0,"IMAGE"],[34,12,2,17,1,"VAE"],[38,45,0,11,4,"INT"],[41,45,0,10,4,"INT"],[43,47,0,10,5,"INT"],[44,47,0,11,5,"INT"],[45,4,0,50,0,"MODEL"],[46,4,1,50,1,"CLIP"],[50,50,0,51,0,"MODEL"],[51,50,1,51,1,"CLIP"],[52,52,0,6,0,"CLIP"],[53,52,0,7,0,"CLIP"],[54,51,1,52,0,"*"],[55,51,0,10,0,"MODEL"]],"groups":[{"id":1,"title":"Base Prompt","bounding":[540.4990234375,178.04730224609375,252,361],"color":"#3f789e","font_size":24,"flags":{}},{"id":2,"title":"Refiner Prompt","bounding":[1441.36474609375,-389.1191101074219,282,372],"color":"#3f789e","font_size":24,"flags":{}},{"id":3,"title":"Text Prompts","bounding":[105,45,339,622],"color":"#3f789e","font_size":24,"flags":{}},{"id":4,"title":"Load in BASE SDXL Model","bounding":[94.8154525756836,-401.56787109375,369,399],"color":"#a1309b","font_size":24,"flags":{}},{"id":5,"title":"Load in REFINER SDXL Model","bounding":[1000.6251831054688,-402.5233154296875,391,400],"color":"#a1309b","font_size":24,"flags":{}},{"id":6,"title":"Empty Latent Image","bounding":[525,570,339,443],"color":"#a1309b","font_size":24,"flags":{}},{"id":7,"title":"VAE Decoder","bounding":[1734.9561767578125,34.404518127441406,360,350],"color":"#b06634","font_size":24,"flags":{}},{"id":8,"title":"Step Control","bounding":[1010.2978515625,575.962890625,284,524],"color":"#3f789e","font_size":24,"flags":{}},{"id":9,"title":"LoRA","bounding":[532.2352905273438,-404.217529296875,391,400],"color":"#a1309b","font_size":24,"flags":{}}],"config":{},"extra":{"ds":{"scale":1.1419980000000205,"offset":[-15.575208669956053,-14.343347306727408]}},"version":0.4}